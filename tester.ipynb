{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=13, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "n_fts = 32\n",
    "n_hid = 2 * n_fts\n",
    "\n",
    "## Neural Network / MLP\n",
    "\n",
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_fts, n_hid): # Define layers in the constructor\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, n_hid, bias=True)     # set bias = True to include it\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_hid, n_fts, bias=True)    # set bias = True to include it\n",
    "        self.fc3 = nn.Linear(n_fts, 1, bias=True)\n",
    "        \n",
    "    def forward(self, x): # Define forward pass in the forward method\n",
    "        # print('lin', self.fc1.weight.dtype)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(n_fts, n_hid)\n",
    "\n",
    "# Dataloader helper\n",
    "class MLPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "# Hyperparams for model\n",
    "lr = 1e-2\n",
    "reg_val = 1e-4\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=reg_val)\n",
    "\n",
    "# Define function to call for each training epoch (one complete pass over the training set)\n",
    "# (sourced from /lecture/fmnist_mlp_torch.ipynb of Course Github)\n",
    "def train(model, trainloader, criterion, optimizer, device, disable=True): #disable controls tqdm visibility\n",
    "    model.train() # set model to training mode\n",
    "    running_loss = 0\n",
    "    with tqdm(total=len(trainloader), desc=f\"Train\", unit=\"batch\", disable=disable) as pbar:\n",
    "        # print(trainloader)\n",
    "        for n_batch, (samples, labels) in enumerate(trainloader): # Iterate over batches\n",
    "            samples, labels = samples.to(device), labels.to(device) # Move batch to device\n",
    "            optimizer.zero_grad()\n",
    "            samples = samples.to(torch.float32)\n",
    "            labels = labels.to(torch.float32)\n",
    "            # print('Sample', labels.dtype)\n",
    "            output = model(samples) # Forward pass\n",
    "            loss = criterion(output, labels) # Compute loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            pbar.update() # Update progress bar\n",
    "    return np.sqrt(running_loss) / len(trainloader) # return RMSE loss\n",
    "\n",
    "# Define function to call for each validation epoch (one complete pass over the validation set)\n",
    "# (sourced from /lecture/fmnist_mlp_torch.ipynb of Course Github)\n",
    "def validate(model, valloader, criterion, device, disable=True): #disable controls tqdm visibility\n",
    "    model.eval() # set model to evaluation mode (e.g. turn off dropout, batchnorm, etc.)\n",
    "    running_loss = 0\n",
    "    with torch.no_grad(): # no need to compute gradients for validation\n",
    "        with tqdm(total=len(valloader), desc=f\"Eval\", unit=\"batch\", disable=disable) as pbar:\n",
    "            for n_batch, (samples, labels) in enumerate(valloader): # Iterate over batches\n",
    "                samples, labels = samples.to(device), labels.to(device) # Move batch to device\n",
    "                samples = samples.to(torch.float32)\n",
    "                labels = labels.to(torch.float32)\n",
    "                output = model(samples) # Forward pass\n",
    "                loss = criterion(output, labels) # Compute loss\n",
    "                running_loss += loss.item() \n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "                pbar.update() # Update progress bar\n",
    "    return np.sqrt(running_loss) / len(valloader)  # return RMSE loss\n",
    "\n",
    "## Set device for training\n",
    "# (sourced from /lecture/fmnist_mlp_torch.ipynb of Course Github)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model.to(device) # Move model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Batch size = 16\n",
      "Epoch 1 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 2 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01f0>\n",
      "Epoch 3 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 4 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 5 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0190>\n",
      "Epoch 6 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 7 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 8 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0160>\n",
      "Epoch 9 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 10 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 11 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01c0>\n",
      "Epoch 12 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 13 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 14 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01c0>\n",
      "Epoch 15 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 16 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 17 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef00a0>\n",
      "Epoch 18 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 19 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 20 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0190>\n",
      "Epoch 21 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 22 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 23 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0160>\n",
      "Epoch 24 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 25 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 26 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef00a0>\n",
      "Epoch 27 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 28 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 29 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0190>\n",
      "Epoch 30 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0160>\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Batch size = 32\n",
      "Epoch 1 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 2 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 3 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 4 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 5 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n",
      "Epoch 6 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 7 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 8 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 9 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n",
      "Epoch 10 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 11 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 12 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n",
      "Epoch 13 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 14 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 15 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n",
      "Epoch 16 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 17 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 18 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n",
      "Epoch 19 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 20 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 21 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n",
      "Epoch 22 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 23 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 24 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed2e0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 26 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 27 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 28 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 29 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 30 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Batch size = 64\n",
      "Epoch 1 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 2 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 3 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0070>\n",
      "Epoch 4 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 5 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 6 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 7 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 8 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 9 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0190>\n",
      "Epoch 10 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 11 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0070>\n",
      "Epoch 12 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 13 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 14 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 15 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 16 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 17 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0190>\n",
      "Epoch 18 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 19 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 20 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 21 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0040>\n",
      "Epoch 22 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 23 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 24 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 25 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 26 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed280>\n",
      "Epoch 27 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0190>\n",
      "Epoch 28 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([38])) that is different to the input size (torch.Size([38, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([102])) that is different to the input size (torch.Size([102, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 30 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Batch size = 128\n",
      "Epoch 1 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 2 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 3 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 4 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 5 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 6 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 7 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 8 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 9 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 10 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 11 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 12 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 13 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 14 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 15 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 16 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 17 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 18 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 19 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 20 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 21 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 22 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 23 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 24 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 25 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 26 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 27 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 28 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa040>\n",
      "Epoch 29 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed430>\n",
      "Epoch 30 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Batch size = 256\n",
      "Epoch 1 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01c0>\n",
      "Epoch 2 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 3 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 4 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed340>\n",
      "Epoch 5 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 6 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 7 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef00d0>\n",
      "Epoch 8 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef0130>\n",
      "Epoch 9 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed8b0>\n",
      "Epoch 10 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef00d0>\n",
      "Epoch 11 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 12 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01f0>\n",
      "Epoch 13 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 14 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01c0>\n",
      "Epoch 15 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef00d0>\n",
      "Epoch 16 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 17 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01f0>\n",
      "Epoch 18 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 19 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01c0>\n",
      "Epoch 20 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eef01f0>\n",
      "Epoch 21 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 22 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 23 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed220>\n",
      "Epoch 24 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 25 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 26 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed340>\n",
      "Epoch 27 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "Epoch 28 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa0a0>\n",
      "Epoch 29 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eeed400>\n",
      "Epoch 30 of 30\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x14eefa070>\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([148])) that is different to the input size (torch.Size([148, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "# dataset = MLPDataset(X, y)\n",
    "\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "trainset = MLPDataset(X_train, y_train)\n",
    "valset = MLPDataset(X_val, y_val)\n",
    "testset = MLPDataset(X_test, y_test)\n",
    "\n",
    "# Run training and validation loop\n",
    "# Save the quickest model to converge\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "## Vary batchsizes for smallest run-time\n",
    "# Sample batchsizes for training  \n",
    "batchsizes_dict = {16: None, 32: None, 64: None, 128: None, 256: None} # to store runtimes\n",
    "rts = [] # for runtimes\n",
    "\n",
    "for B in batchsizes_dict:\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(f\"Batch size = {B}\")\n",
    "\n",
    "    seeder = 33\n",
    "\n",
    "    # refresh model for a fair iteration\n",
    "    model = MLP(n_fts, n_hid)\n",
    "    model.to(device)\n",
    "    # for refreshed model\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=reg_val)\n",
    "\n",
    "    best_rmse = 1000\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    # time marker\n",
    "    start = time()\n",
    "    # Iterate over epochs\n",
    "    # (sourced from /lecture/fmnist_mlp_torch.ipynb of Course Github)\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch+1} of {n_epochs}\")\n",
    "        seeder += 1\n",
    "        # Shuffle the data at the start of each epoch (only useful for training set)\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=B, shuffle=True, worker_init_fn=lambda id: np.random.seed(id+seeder))\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=B, shuffle=False, worker_init_fn=lambda id: np.random.seed(id+seeder))\n",
    "        \n",
    "        train_loss = train(model, trainloader, criterion, optimizer, device, disable=True) # Train\n",
    "        val_loss = validate(model, valloader, criterion, device, disable=True) # Validate\n",
    "        # mark the end of this epoch's training\n",
    "        runtime = time() - start\n",
    "        train_loss_history.append(train_loss)\n",
    "        val_loss_history.append(val_loss)\n",
    "        if val_loss < best_rmse: # Save best model\n",
    "            # print(\"Updating best model\")\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model_pts.pt\") # saving model parameters (\"state_dict\") saves memory\n",
    "        # if val_loss <= 3 and train_loss <= 3: # stop at 80% accuracy\n",
    "        #     runtime_model = runtime\n",
    "        #     print(\"Attained Stopping Condition\")\n",
    "        #     break\n",
    "    \n",
    "    # rts.append(runtime_model)\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "# B_opt = min(batchsizes_dict, key=batchsizes_dict.get)\n",
    "# print(f\"Batch size of {B_opt} converges the fastest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7])\n",
    "\n",
    "a = a.reshape(len(a), 1)\n",
    "b = b.reshape(len(b), 1)\n",
    "\n",
    "c = np.vstack((a,b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([[0]])\n",
    "d = np.vstack((d, c))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5495098"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_a = np.array([1, 2, 3, 4])\n",
    "np_d = np.array([1, 2, 3, 4])\n",
    "np_b = np.array([3, 4, 5, 6])\n",
    "np_c = np.array([4, 5, 6, 7])\n",
    "\n",
    "a_ = np_a.reshape(4, 1)\n",
    "b_ = np_b.reshape(4, 1)\n",
    "c_ = np_c.reshape(4, 1)\n",
    "d_ = np_d.reshape(4, 1)\n",
    "\n",
    "a = torch.from_numpy(a_)\n",
    "b = torch.from_numpy(b_)\n",
    "c = torch.from_numpy(c_)\n",
    "d = torch.from_numpy(d_)\n",
    "\n",
    "a = a.to(torch.float32)\n",
    "b = b.to(torch.float32)\n",
    "c = c.to(torch.float32)\n",
    "d = d.to(torch.float32)\n",
    "\n",
    "ab = np.vstack((a,b))\n",
    "cd = np.vstack((c,d))\n",
    "\n",
    "mean_squared_error(np_a, np_b, squared=False)\n",
    "mean_squared_error(np_d, np_c, squared=False)\n",
    "mean_squared_error(ab, cd, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5495097567963922"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = nn.MSELoss()\n",
    "loss1 = crit(a, b) * 4\n",
    "loss2 = crit(c, d) * 4\n",
    "\n",
    "loss = np.sqrt((loss2.item() + loss1.item())/8)\n",
    "loss\n",
    "# np.sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = None\n",
    "x == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         x[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(\u001b[39m0\u001b[39m ,x[i])\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m----> 6\u001b[0m a \u001b[39m=\u001b[39m testrelu(arr)\n\u001b[1;32m      7\u001b[0m a\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mtestrelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtestrelu\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x)):\n\u001b[0;32m----> 3\u001b[0m         x[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmax(\u001b[39m0\u001b[39;49m ,x[i])\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2705\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2706\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2821\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ee559/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "def testrelu(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = np.max(0 ,x[i])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "ll = np.array(lll)\n",
    "ll = np.floor(ll/5).astype(int)\n",
    "ll = ll * 5\n",
    "ll = ll.tolist()\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = [1,2,3,4,5]\n",
    "min(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee559",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
